{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SegNet Implementation - Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importacion de librerÃ­as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from __future__ import print_function\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss2d(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(CrossEntropyLoss2d, self).__init__()\n",
    "        self.nll_loss = nn.NLLLoss2d(weight, size_average)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        return self.nll_loss(F.log_softmax(inputs), targets)\n",
    "\n",
    "\n",
    "def CrossEntropy2d(input, target, weight=None, size_average=False):\n",
    "    # input:(n, c, h, w) target:(n, h, w)\n",
    "    n, c, h, w = input.size()\n",
    "\n",
    "    input = input.transpose(1, 2).transpose(2, 3).contiguous()\n",
    "    input = input[target.view(n, h, w, 1).repeat(1, 1, 1, c) >= 0].view(-1, c)\n",
    "\n",
    "    target_mask = target >= 0\n",
    "    target = target[target_mask]\n",
    "    #loss = F.nll_loss(F.log_softmax(input), target, weight=weight, size_average=False)\n",
    "    loss = F.cross_entropy(input, target, weight=weight, size_average=False)\n",
    "    if size_average:\n",
    "        loss /= target_mask.sum().data[0]\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeftVentricleDataset(Dataset):\n",
    "    def __init__(self, transform = None):\n",
    "        \n",
    "        data = sio.loadmat('cardiac-dig.mat')\n",
    "        images_LV = data['images_LV']\n",
    "        endo_LV = data['endo_LV']\n",
    "        epi_lv = data['epi_LV']\n",
    "        lv_phase = data['lv_phase']\n",
    "        rwt = data['rwt']\n",
    "        areas = data['areas']\n",
    "        dims = data['dims']\n",
    "        \n",
    "        # 1 - MRI Left Ventricle\n",
    "        # Swap of indices to use in PyTorch\n",
    "        images_LV_m = np.swapaxes(images_LV,0,2)\n",
    "        images_LV_m = np.swapaxes(images_LV_m, 1, 2)\n",
    "        images_LV_m = torch.from_numpy(images_LV_m)\n",
    "        self.images_LV = images_LV_m\n",
    "        self.images_LV = images_LV_m[0:2020, : ,:]\n",
    "        \n",
    "        # 2 - Cardiac phase\n",
    "        self.lv_phase = torch.from_numpy(lv_phase.flatten('C'))\n",
    "        self.lv_phase = self.lv_phase[0:2020]\n",
    "        \n",
    "        # 3 - RWT (6 indices)\n",
    "        self.rwt = torch.from_numpy(rwt)\n",
    "        self.rwt = self.rwt[:, 0:2020]\n",
    "        \n",
    "        # 4 - Areas (cavity and myocardium)\n",
    "        self.areas = torch.from_numpy(areas)\n",
    "        self.areas = self.areas[:, 0:2020]\n",
    "        \n",
    "        # 5 - Dims\n",
    "        self.dims = torch.from_numpy(dims)\n",
    "        self.dims = self.dims[:, 0:2020]\n",
    "        \n",
    "        # 6 - Endo (segmentation)\n",
    "        endo_LV_m = np.swapaxes(endo_LV,0,2)\n",
    "        endo_LV_m = np.swapaxes(endo_LV_m, 1, 2)\n",
    "        endo_LV_m = torch.from_numpy(endo_LV_m)\n",
    "        self.endo_LV = endo_LV_m\n",
    "        self.endo_LV = endo_LV_m[0:2020, : ,:]\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image_lv = self.images_LV[index, :, :]\n",
    "        \n",
    "        endo_lv = self.endo_LV[index, :, :]\n",
    "        \n",
    "        phase_lv = self.lv_phase[index]\n",
    "        \n",
    "        rwt = self.rwt[:, index]\n",
    "        \n",
    "        areas = self.areas[:, index]\n",
    "        \n",
    "        dims = self.dims[:, index]\n",
    "        \n",
    "        sample = {'images_lv': image_lv, 'endo_lv': endo_lv, 'phase_lv': phase_lv, \n",
    "                  'rwt_lv': rwt, 'areas_lv': areas, 'dims_lv': dims}\n",
    "        \n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images_LV.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_lv = LeftVentricleDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = dataset_lv, batch_size = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SegNet - ArXiv: https://arxiv.org/pdf/1511.00561.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SegNet, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(1, 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, return_indices = True)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, return_indices = True)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, return_indices = True)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, return_indices = True)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, return_indices = True)\n",
    "        \n",
    "        self.unpool5 = nn.MaxUnpool2d(kernel_size = 2, stride = 2, padding = 0)\n",
    "        self.unpool4 = nn.MaxUnpool2d(kernel_size = 2, stride = 2, padding = 0)\n",
    "        self.unpool3 = nn.MaxUnpool2d(kernel_size = 2, stride = 2, padding = 0)\n",
    "        self.unpool2 = nn.MaxUnpool2d(kernel_size = 2, stride = 2, padding = 0)\n",
    "        self.unpool1 = nn.MaxUnpool2d(kernel_size = 2, stride = 2, padding = 0)\n",
    "\n",
    "        self.deconv5_1 = nn.ConvTranspose2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv5_2 = nn.ConvTranspose2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv5_3 = nn.ConvTranspose2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv4_1 = nn.ConvTranspose2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv4_2 = nn.ConvTranspose2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv4_3 = nn.ConvTranspose2d(512, 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv3_1 = nn.ConvTranspose2d(256, 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv3_2 = nn.ConvTranspose2d(256, 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv3_3 = nn.ConvTranspose2d(256, 128, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv2_1 = nn.ConvTranspose2d(128, 128, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv2_2 = nn.ConvTranspose2d(128, 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv1_1 = nn.ConvTranspose2d(64, 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv1_2 = nn.ConvTranspose2d(64, 2, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(128)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(256)\n",
    "        self.batch_norm4 = nn.BatchNorm2d(512)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        size_1 = x.size()\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv1_2(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(x)\n",
    "        x, idxs1 = self.pool1(x)\n",
    "        \n",
    "        size_2 = x.size()\n",
    "        x = self.conv2_1(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2_2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.relu(x)\n",
    "        x, idxs2 = self.pool2(x)\n",
    "        \n",
    "        size_3 = x.size()\n",
    "        x = self.conv3_1(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3_2(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3_3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = F.relu(x)\n",
    "        x, idxs3 = self.pool3(x)\n",
    "        \n",
    "        size_4 = x.size()\n",
    "        x = self.conv4_1(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4_2(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4_3(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x, idxs4 = self.pool4(x)\n",
    "        \n",
    "        size_5 = x.size()\n",
    "        x = self.conv5_1(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5_2(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5_3(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x, idxs5 = self.pool5(x)\n",
    "\n",
    "        \n",
    "        x = self.unpool5(x, idxs5, output_size = size_5)\n",
    "        x = self.deconv5_1(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv5_2(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv5_3(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.unpool4(x, idxs4, output_size = size_4)\n",
    "        x = self.deconv4_1(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv4_2(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv4_3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.unpool3(x, idxs3, output_size = size_3)\n",
    "        x = self.deconv3_1(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv3_2(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv3_3(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.unpool2(x, idxs2, output_size = size_2)\n",
    "        x = self.deconv2_1(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv2_2(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.unpool1(x, idxs1, output_size = size_1)\n",
    "        x = self.deconv1_1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv1_2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 3500\n",
    "model = SegNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.9, weight_decay = 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 2, 80, 80)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3500], Loss:0.6303\n",
      "Epoch [1/3500], Loss:0.4070\n",
      "Epoch [1/3500], Loss:0.3319\n",
      "Epoch [1/3500], Loss:0.1834\n",
      "Epoch [1/3500], Loss:0.4049\n",
      "Epoch [1/3500], Loss:0.1089\n",
      "Epoch [1/3500], Loss:0.0667\n",
      "Epoch [1/3500], Loss:0.1085\n",
      "Epoch [1/3500], Loss:0.0561\n",
      "Epoch [1/3500], Loss:0.0432\n",
      "Epoch [1/3500], Loss:0.1665\n",
      "Epoch [1/3500], Loss:0.0671\n",
      "Epoch [1/3500], Loss:0.0986\n",
      "Epoch [1/3500], Loss:0.0607\n",
      "Epoch [1/3500], Loss:0.0612\n",
      "Epoch [1/3500], Loss:0.0641\n",
      "Epoch [1/3500], Loss:0.1452\n",
      "Epoch [1/3500], Loss:0.0572\n",
      "Epoch [1/3500], Loss:0.0838\n",
      "Epoch [1/3500], Loss:0.0357\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-61c574d7c888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alejandrodebus/anaconda2/envs/cv/lib/python2.7/site-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alejandrodebus/anaconda2/envs/cv/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        img = data['images_lv']\n",
    "        img = torch.unsqueeze(img, 1)\n",
    "        img = img.type(torch.FloatTensor)\n",
    "        \n",
    "        label_endo = data['endo_lv']\n",
    "        label_endo = torch.unsqueeze(label_endo, 1)\n",
    "        label_endo = label_endo.type(torch.LongTensor)\n",
    "        \n",
    "        optimizer.zero_grad() # eliminar gradientes acumulados\n",
    "        \n",
    "        # Forward\n",
    "        output_r = model(img)\n",
    "        output = output_r.view(output_r.size(0),output_r.size(1), -1)\n",
    "        output = torch.transpose(output,1,2).contiguous()\n",
    "        output = output.view(-1, output.size(2))\n",
    "        label_endo = label_endo.view(-1)\n",
    "        loss = criterion(output, label_endo)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Epoch [{}/{}], Loss:{:.4f}'\n",
    "                .format(epoch+1, num_epochs, loss.data))\n",
    "            \n",
    "        if epoch % 1 == 0:\n",
    "            pic = to_img(output_r.data)\n",
    "            #prediction = output_r.data.max(1)[1].squeeze_(1).squeeze_(0).cpu().numpy()\n",
    "            #prediction = voc.colorize_mask(prediction)\n",
    "            #print(prediction.shape)\n",
    "            save_image(pic[1,1,:,:], './img_segnet/image_{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cv)",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
